---
title: 'Causal Inference Runs the World: Or, What Are "Actionable Insights", Anyways?'
date: 2025-03-07
categories: [Econometrics, Causal Inference, Data Science]
---

# What Even Are Actionable Insights?

Man, I hate industry jargon. Don't get me wrong, I'm not against all jargon. I've been in academia ten years, and I've spent maybe 6 of those being tormented by econometrics. We have our own jargon too, which doesn't always jive well with industry- I say "causal inference", marketers will say "incrementality testing". Maybe it's because I dislike corporate culture in general, but there's something about the data science industry lingo that irritates me. "Ambiguity" (I'll do a post on this one, one day). "Self starter". "_Business acumen_". And the favorite of the day, "actionable insights." This post is dedicated to showing you how I think about actionable insights, from the perspective of somebody who cares a lot about causal inference.

"Actionable insights". It's the one we hear about all the time, even if it isn't phrased quite like that. Job descriptions and data science pages will go on and on about how we're meant to deliver them as econometricians, policy analysts, and data scientists, staking our livelihoods to them. But, what are actionable insights anyways? [Some pages](https://loop-software.com/news-and-insights/what-are-actionable-insights) say "“Actionable insights” describes contextualised data analysis. It’s a piece of information that can actually be put into action — supported by the analysis, context and communication tools required to get the job done." I agree with this. This leads us to one question then: what is an insight and whatmakes an insight actionable? 

## A Motivating Example

Recently [I saw a post on LinkedIn](https://www.linkedin.com/posts/jared-greathouse-26315711a_data-science-intern-heres-a-bar-chart-activity-7301645259157970946-kJ_T?utm_source=share&utm_medium=member_desktop&rcm=ACoAAB2Q8asBlsCYlwKJgJ488VWbcV1CX14FdOw). It went something like this:

> Data Science Intern: "The chart shows that downloading of the App increased by 45%." Client: "So?"

>  Junior Data Scientist: "The chart shows that downloading of the App increased by 45%, compared to the same time yesteryear." Client:  "Great! Why?"

> Principal Data Scientist: "The chart shows that downloading of the App increased by 45%, compared to the same time yesteryear due to our new pricing strategy. We should roll out Pricing Strategy in more markets since it'll likely increase revenue by Big Amount." Client:  "That's great! We'll get right to it."

In context, the post was about connecting your results to the next steps of actions businesses/clients should take. And that's great, we should all be doing that. But I find the hypothetical Principal DS's answer to be quite wanting. I do not understand why we are meant to see the Principal DS's remarks as any more wise than the Junior DS. Why? The Principal DS was making a counterfactual claim, implicitly. They were explaining to the client that their Policy W had X impact on Outcome Y, an even went as far as to say that if we kept doing Policy W, we may see gains elsewhere in the future. And this may be true, but how can we tell? For all the talk we have about showing impact in our resumes and results (instead of "I did X", do "I did X which had X impact on efficiency"), surely we can do better than this. How? Causal inference.

My issue with the post was this: the second you add the phrase "Impact X happened _given our new pricing strategy/policy/other intervention_", we're now very far aflung from Descriptiville, stuck in Counterfactual Land. In this domain, the governance is a bit different than simply getting Tableau/BI to make us a chart: here you see, we need to have some estimate of how sales (or whatever metric we're meant to care about) would've evolved ABSENT whatever the new policy was. Put differently, you can't just show a bar chart and say "You should do X cuz I made this chart and have verbally attached a reason to a number". It requires A LOT more work than that.

# Actionable Insights, Econometrics Style

a factor model structure with a treatment intervention at a specific time period. Let $\mathbf{Y}_{t}$ be the $n \times 1$ vector of observed outcomes (e.g., sales) for \(n\) markets at time \(t\), and let \(\mathbf{F}_{t}\) be a \(k \times 1\) vector of unobserved common factors. The factor model is given by:  

$$
\mathbf{y}_{j} = \mathbf{\Lambda} \mathbf{F}_{t} + \boldsymbol{\epsilon}_{t}
$$

where $\mathbf{\Lambda}$ is an $n \times k$ matrix of factor loadings, and $\boldsymbol{\epsilon}_{t} \sim \mathcal{N}(\mathbf{0}, \sigma^2 \mathbf{I}_n)$ is an idiosyncratic error term. The common factors evolve according to an autoregressive process:  

$$
\mathbf{F}_{t} = \rho \mathbf{F}_{t-1} + \boldsymbol{\eta}_{t}, \quad \boldsymbol{\eta}_{t} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}_k).
$$

The observed sales data for any given unit is a vector, $\mathbf{y}_{j}$, generated as a function of these latent factors and the idiosyncratic shocks. The treated unit, indexed by $i=0$, receives a treatment effect $\tau$ starting at time $T_0$:  

$$
y_{0t} = \Lambda_{0} \mathbf{F}_{t} + \epsilon_{0t} + \tau \mathbb{1}(t \geq T_0).
$$


