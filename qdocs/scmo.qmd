---
title: "Synthetic Control Methods With Multiple Outcomes"
date: 2025-04-14
categories: [Causal Inference, Econometrics]
---

Sometimes, analysts have multiple different metrics at their disposal with which to estimate synthetic control models. That is, multiple relevant variables may predict a single target/outcome variable that we care about. However, most people who use synthetic controls use only a single outcome in their analyses. Recent papers by econometricians have extended the standard model to incorporating multiple outcomes into the objective function, and a few recent [recent](https://doi.org/10.48550/arXiv.2311.16260) [papers](https://doi.org/10.48550/arXiv.2304.02272) have advocated for this in applied settings. This blog demonstrates this apporach for ```mlsynth```.

# Notation

Let $\mathbb{R}$ denote the set of real numbers. A calligraphic letter, such as $\mathcal{S}$, represents a discrete set with cardinality $S = |\mathcal{S}|$. When multiplying a matrix $\mathbf{A} \in \mathbb{R}^{T \times N_0}$ by a vector $\mathbf{b} \in \mathbb{R}^{N_0}$, the result is a new vector in $\mathbb{R}^T$, formed as a linear combination of the columns of $\mathbf{A}$:

$$
\mathbf{A} \mathbf{b} = \sum_{j \in \mathcal{N}_0} b_j \mathbf{A}_{:,j} \in \mathbb{R}^T
$$

Here, each entry in the resulting vector is a dot product between a row of $\mathbf{A}$ and the vector $\mathbf{b}$.

Let $j \in \mathbb{N}$ represent indices for a total of $N$ units and $t \in \mathbb{N}$ index time. Let $j = 1$ denote the treated unit, with the set of controls being $\mathcal{N}_0 = \mathcal{N} \setminus \{1\}$, with cardinality $N_0$. The pre-treatment period consists of the set $\mathcal{T}_1 = \{ t \in \mathbb{N} : t \leq T_0 \}$, where $T_0$ is the final period before treatment. Similarly, the post-treatment period is given by $\mathcal{T}_2 = \{ t \in \mathbb{N} : t > T_0 \}$.

The observed outcome for unit $j$ at time $t$ is $y_{jt}$, where a generic outcome vector for a given unit in the dataset is:

$$
\mathbf{y}_j \in \mathbb{R}^T, \quad \mathbf{y}_j = (y_{j1}, y_{j2}, \dots, y_{jT})^\top \in \mathbb{R}^T
$$

The outcome vector for the treated unit specifically is $\mathbf{y}_1$. The donor matrix is defined as:

$$
\mathbf{Y}_0 \coloneqq \begin{bmatrix} \mathbf{y}_j \end{bmatrix}_{j \in \mathcal{N}_0} \in \mathbb{R}^{T \times N_0}
$$

where each column indexes a donor unit and each row corresponds to a time period. We denote by $\mathbf{y}_j^{\text{pre}} \in \mathbb{R}^{T_0}$ the subvector of outcomes for unit $j$ in the pre-treatment period, and by $\mathbf{y}_j^{\text{post}} \in \mathbb{R}^{T_1}$ the corresponding post-treatment vector, where $T_1 = T - T_0$. Then, we define our pre- and post-intervention analogs for the data:

$$
\mathbf{y}_1^{\text{pre}} = (y_{1t})_{t \in \mathcal{T}_1} \in \mathbb{R}^{T_0}, \quad \mathbf{y}_1^{\text{post}} = (y_{1t})_{t \in \mathcal{T}_2} \in \mathbb{R}^{T_1}
$$

$$
\mathbf{Y}_0^{\text{pre}} = \left[ \mathbf{y}_j^{\text{pre}} \right]_{j \in \mathcal{N}_0} \in \mathbb{R}^{T_0 \times N_0}, \quad \mathbf{Y}_0^{\text{post}} = \left[ \mathbf{y}_j^{\text{post}} \right]_{j \in \mathcal{N}_0} \in \mathbb{R}^{T_1 \times N_0}
$$

We aim to find weights $\mathbf{w} \in \mathbb{R}^{N_0}$ subject to

$$
\mathbf{w} \in \mathcal{W} = \left\{ \mathbf{w} \in \mathbb{R}_{\geq 0}^{N_0} : \|\mathbf{w}\|_1 = 1 \right\}
$$

which minimize the mean squared error between the target vector and pre-intervention fit.

The exact same notations apply for the case of multiple outcomes. Let $k$ denote the number of outcomes aside from the main one being used. For each outcome $m \in \{1, 2, \dots, k\}$, we have:

$$
\mathbf{Y}_0^{(m)} \in \mathbb{R}^{T \times N_0} \quad \text{and} \quad \mathbf{y}_1^{(m)} \in \mathbb{R}^{T}
$$

where $\mathbf{Y}_0^{(m)}$ is the donor matrix for outcome $m$, and $\mathbf{y}_1^{(m)}$ is the outcome vector for the treated unit for the $m$-th outcome. Similarly, for the pre-treatment and post-treatment periods, we define:

$$
\mathbf{Y}_0^{(m), \text{pre}} \in \mathbb{R}^{T_0 \times N_0}, \quad \mathbf{Y}_0^{(m), \text{post}} \in \mathbb{R}^{T_1 \times N_0}
$$

and

$$
\mathbf{y}_1^{(m), \text{pre}} \in \mathbb{R}^{T_0}, \quad \mathbf{y}_1^{(m), \text{post}} \in \mathbb{R}^{T_1}
$$

At first, the multiple outcomes setup may seem intimidating. In every application of synthetic control I have worked with, along with most analysts I imagine, we have worked with a single outcome at a time. However, best way to think about it is that we are simply horizontally stacking matrices and vectors atop one another and using the latent factors embedded within each of those outcomes to predict the pre-intervention time series for the main metric we do care about. I define the "stacking" operation, denoted by the prime notation, as the concatenation of matrices or vectors along their rows. Specifically, the stacked version of a matrix is given by:

$$
\mathbf{A}' = \begin{bmatrix} \mathbf{A}_1 \\ \mathbf{A}_2 \\ \vdots \\ \mathbf{A}_k \end{bmatrix}
$$
where $\mathbf{A}_i$ are matrices or vectors to be stacked, and the resulting matrix $\mathbf{A}'$ has rows corresponding to each of the matrices being stacked. Similarly, for vectors we have

$$
\mathbf{v}' = \begin{bmatrix} \mathbf{v}_1 \\ \mathbf{v}_2 \\ \vdots \\ \mathbf{v}_k \end{bmatrix}
$$
where each $\mathbf{v}_i$ is a vector to be stacked, and the resulting vector $\mathbf{v}'$ is formed by stacking these vectors.

We solve the following objective function for the stacked synthetic control:

$$
\underset{\mathbf{w} \in \mathcal{W}}{\operatorname*{argmin}} \left\| \mathbf{Y}_0' \mathbf{w} - \mathbf{y}_1' \right\|^2
$$

where $\mathbf{Y}_0'$ is the stacked matrix of donor unit outcomes across all outcomes, and $\mathbf{y}_1'$ is the stacked vector of treated unit outcomes across all outcomes. More specifically:

$$
\mathbf{Y}_0' = \begin{bmatrix} \mathbf{Y}_0^{(1)} \\ \mathbf{Y}_0^{(2)} \\ \vdots \\ \mathbf{Y}_0^{(k)} \end{bmatrix}, \quad
\mathbf{y}_1' = \begin{bmatrix} \mathbf{y}_1^{(1)} \\ \mathbf{y}_1^{(2)} \\ \vdots \\ \mathbf{y}_1^{(k)} \end{bmatrix}
$$


To account for intercept shifts, we similarly minimize the following:

$$
\underset{\mathbf{w} \in \mathcal{W}}{\operatorname*{argmin}} \left\| \mathbf{Y}_0' \mathbf{w} - \boldsymbol{\beta} \mathbf{1}_T - \mathbf{y}_1' \right\|^2
$$

In this case, $\boldsymbol{\beta}$ represents a vector of intercepts, and $\mathbf{1}_T$ is a vector of ones with length $T$. The term $\mathbf{Y}_0'$ is the stacked matrix of donor outcomes, and $\mathbf{y}_1'$ is the stacked vector of treated unit outcomes, as defined earlier.

# Estimation in Python

```{python}

#| fig-align: center
#| echo: false

import numpy as np
import pandas as pd

from mlsynth.mlsynth import SCMO

def simulate(
    N=99, T0=52*3, T1=52, K=4, r=3, sigma=.20,
    max_gamma=.5, T_season=12, seed=34305
):
    np.random.seed(seed)
    T = T0 + T1

    # Latent factors
    phi = np.random.normal(0, 1, size=(N, r))           # Market-specific latent factors
    mu = np.random.normal(0, 1, size=(T, K, r))          # Time-and-outcome-specific latent factors

    # Fixed effects
    alpha = np.random.normal(0, 1, size=(N, K))          # Market fixed effects
    beta = np.random.normal(0, 1, size=(T, K))           # Time fixed effects

    # Market-specific seasonal parameters
    gamma_i = np.random.uniform(0, max_gamma, size=N)    # amplitude of seasonal effect
    tau_i = np.random.randint(0, T_season, size=N)       # phase shift (peak week)

    # Construct seasonal matrix S (N x T): market-time-specific seasonality
    t_grid = np.arange(T)
    S = np.array([
        gamma_i[i] * np.cos(4 * np.pi * (t_grid - tau_i[i]) / T_season)
        for i in range(N)
    ])

    # Initialize outcome matrix
    Y = np.zeros((N, T, K))

    # Define baseline offsets for each outcome with random integers between 200 and 500
    baseline_shift = [np.random.randint(200, 500) for _ in range(K)]  # Random base values for each outcome

    # Autocorrelation coefficients for each outcome
    rho = np.array([0.8, 0.6, 0.5, 0.3])  # AR(1) coefficients for each outcome

    # Generate outcomes with autocorrelation
    for k in range(K):
        latent = phi @ mu[:, k, :].T  # N x T
        base = (
            alpha[:, [k]] +         # N x 1
            beta[:, k] +            # T,
            latent +                # N x T
            S +                     # N x T
            baseline_shift[k]       # scalar
        )
        noise = np.random.normal(0, sigma, size=(N, T))

        # First time point initialization
        Y[:, 0, k] = base[:, 0] + noise[:, 0]

        # AR(1) recursion
        for t in range(1, T):
            Y[:, t, k] = (
                rho[k] * Y[:, t-1, k] +
                (1 - rho[k]) * base[:, t] +
                noise[:, t]
            )

    # Identify treated market: second-highest on phi[:, 0]
    treated_unit = np.argsort(phi[:, 0])[-2]

    # Vectorized treatment assignment (N x T)
    time = np.arange(T)
    post_treatment = (time >= T0)
    treat = np.zeros((N, T), dtype=int)
    treat[treated_unit, post_treatment] = 1

    # Inject treatment effect into Gross Booking Value for treated market
    Y[treated_unit, post_treatment, 0] += 5  # add treatment effect of +5

    # Construct the dataframe without loops
    markets = np.arange(N)[:, None]           # shape (N, 1)
    weeks = np.arange(T)[None, :]             # shape (1, T)

    market_grid = np.repeat(markets, T, axis=1).flatten()  # shape (N*T,)
    week_grid = np.tile(weeks, (N, 1)).flatten()           # shape (N*T,)


    cities = [
        "São Paulo", "Mexico City", "San Carlos de Bariloche", "Rio de Janeiro", "Ushuaia",
        "Bogotá", "Santiago", "Caracas", "Guayaquil", "Quito",
        "Brasília", "Bocas del Toro", "Asunción", "Cabo San Lucas", "Playa del Carmen",
        "Medellín", "Porto Alegre", "Placencia", "Recife", "Salvador",
        "Zihuatanejo", "San José", "Panama City", "Montevidio", "Tegucigalpa",
        "Foz do Iguaçu", "Maracaibo", "Rosario", "Maracay", "Antofagasta",
        "San Pedro Sula", "San Juan", "Chihuahua", "Cayo District", "Maturín",
        "Buzios", "Puebla", "Mar del Plata", "Arequipa", "Fernando de Noronha", "Guatemala City",
        "Zacatecas", "Mérida", "Córdoba", "Cozumel", "Trujillo",
        "Corozal Town", "Santa Cruz de la Sierra", "San Luis Potosí", "Jalapão", "Potosí",
        "Tucumán", "Neuquén", "La Plata", "Viña del Mar", "Florianópolis", "Lagos de Moreno",
        "La Paz", "Belém", "Venezuela", "Ribeirão Preto", "Valparaíso",
        "Marília", "Campinas", "Vitoria", "Sorocaba", "Santa Fe",
        "San Salvador", "Lima", "Buenos Aires", "Curitiba", "Maceió",
        "Cartagena", "La Ceiba", "Puerto La Cruz", "Olinda", "Monterrey",
        "Ibagué", "Cúcuta", " Paraty", "Cancún", "Puerto Escondido", "Chiclayo", "Ambato",
        "Pucallpa", "Santa Marta", "Villavicencio", "Paraná", "Cauca", "San Vicente",
        "Cali", "Tarija", "Manzanillo", "El Alto", "Santiago de Chile", "Cochabamba",
        "Iquique", "Santo Domingo", "Durango", "Puerto Viejo de Talamanca"
    ]

    city_mapping = {i: cities[i] for i in range(N)}

    data = {
        'Market': [city_mapping[market] for market in market_grid],
        'Week': week_grid,
        'Experiences': treat.flatten()
    }

    for k in range(K):
        if k == 0:
            data['Gross Booking Value'] = Y[:, :, k].flatten()
        elif k == 1:
            data['Average Booking Price'] = Y[:, :, k].flatten()
        elif k == 2:
            data['Average Daily Visitors'] = Y[:, :, k].flatten()
        elif k == 3:
            data['Average Cost of Hotel Rooms'] = Y[:, :, k].flatten()

    return pd.DataFrame(data)

# Run simulation
df = simulate()


config = {
    "df": df,
    "outcome": 'Gross Booking Value',  # Update to the renamed KPI
    "treat": 'Experiences',
    "unitid": 'Market',
    "time": 'Week',
    "display_graphs": True,
    "save": False,
    "counterfactual_color": ["red", "blue"], "addout": list(df.columns[4:]),
    "method": "both"
}

arco = SCMO(config).fit()



```
