---
title: 'A Novel Two Stage Synthetic Control Method'
date: 2025-04-06
categories: [Causal Inference, Econometrics]
---
I define.

# Notation

Let $\mathbb{R}$ denote the set of real numbers. A calligraphic letter, such as $\mathcal{S}$, represents a discrete set with cardinality $S = |\mathcal{S}|$. Let $\mathbf{C}_T \in \mathbb{R}^{T \times T}$ represent the centering matrix defined as:

$$
\mathbf{C}_T \coloneqq \mathbf{I}_T - \frac{1}{T} \mathbf{1}_T \mathbf{1}_T^\top
$$

Where $\mathbf{I}_T$ is the identity matrix of size $T$, and $\mathbf{1}_T \in \mathbb{R}^T$ is the vector of ones of length $T$. For any vector $\mathbf{x} \in \mathbb{R}^T$, the demeaned version is:

$$
\widetilde{\mathbf{x}} \coloneqq \mathbf{C}_T \mathbf{x}
$$ 

For any pair of vectors $\mathbf{a}, \mathbf{b} \in \mathbb{R}^{N_0}$, we define the Hadamard (elementwise) product as $(\mathbf{a} \odot \mathbf{b})_j \coloneqq a_j b_j \quad \text{for each } j \in \mathcal{N}_0$. Let $j \in \mathbb{N}$ represent indices for a total of $N$ units and $t \in \mathbb{N}$ index time. Let $j = 1$ be the treated unit, with the set of controls being $\mathcal{N}_0 = \mathcal{N} \setminus \{1\}$, with cardinality $N_0$. The pre-treatment period consists of the set $\mathcal{T}_1 = \{ t \in \mathbb{N} : t \leq T_0 \}$, where $T_0$ is the final period before treatment. Similarly, the post-treatment period is given by $\mathcal{T}_2 = \{ t \in \mathbb{N} : t > T_0 \}$.

The observed outcome for unit $j$ at time $t$ is $y_{jt}$, where a generic outcome vector for a given unit in the dataset is $\mathbf{y}_j \in \mathbb{R}^T$, with $\mathbf{y}_j = (y_{j1}, y_{j2}, \dots, y_{jT})^\top \in \mathbb{R}^{T}$. The outcome vector for the treated unit specifically is $\mathbf{y}_1$. The donor matrix is defined as $\mathbf{Y}_0 \coloneqq \begin{bmatrix} \mathbf{y}_j \end{bmatrix}_{j \in \mathcal{N}_0} \in \mathbb{R}^{T \times N_0}$, where each column indexes a donor unit and each row is indexed to a time period. We denote by $\mathbf{y}_j^{\text{pre}} \in \mathbb{R}^{T_0}$ the subvector of outcomes for unit $j$ in the pre-treatment period, and by $\mathbf{y}_j^{\text{post}} \in \mathbb{R}^{T_1}$ the corresponding post-treatment vector, where $T_1 = T - T_0$. Then, we define our pre and post intervention analogs for the data:

$$
\mathbf{y}_1^{\text{pre}} = (y_{1t})_{t \in \mathcal{T}_1} \in \mathbb{R}^{T_0}, \quad \mathbf{y}_1^{\text{post}} = (y_{1t})_{t \in \mathcal{T}_2} \in \mathbb{R}^{T_1}
$$

$$
\mathbf{Y}_0^{\text{pre}} = \left[ \mathbf{y}_j^{\text{pre}} \right]_{j \in \mathcal{N}_0} \in \mathbb{R}^{T_0 \times N_0}, \quad \mathbf{Y}_0^{\text{post}} = \left[ \mathbf{y}_j^{\text{post}} \right]_{j \in \mathcal{N}_0} \in \mathbb{R}^{T_1 \times N_0}
$$

## Synthetic Controls

Before I get to the SRC, I review synthetic controls. Let $\mathbf{y}_1 \in \mathbb{R}^T$ represent the outcome vector of the treated unit, where we seek to estimate the counterfactual outcomes in the post-treatment period (i.e., for $t > T_0$). We define the synthetic control as a weighted sum of the donor units' outcome vectors $\mathbf{y}_j$, where $j \in \mathcal{N}_0$. Specifically, we use a weight vector $\mathbf{w} \in \mathbb{R}^{N_0}$ to form the synthetic control, such that the counterfactual outcome for the treated unit is

$$
\mathbf{y}_1^{\text{SC}} = \mathbf{Y}_0 \mathbf{w}
$$

where $\mathbf{y}_1^{\text{SC}}$ is the predicted counterfactual outcome for the treated unit, $\mathbf{Y}_0 \in \mathbb{R}^{T \times N_0}$ is the matrix of outcome vectors for the donor units, and $\mathbf{w} \in \mathbb{R}^{N_0}$ is the vector of weights applied to each donor unit. The goal is to find $\mathbf{w}$ that best approximates the outcome vector of the treated unit during the pre-treatment period.

The weights are estimated by minimizing the distance between the treated unit's pre-treatment outcomes $\mathbf{y}_{1,\text{pre}}$ and the weighted average of the donor units' pre-treatment outcomes. This can be expressed as

$$
\min_{\mathbf{w}} \left\| \mathbf{y}_{1,\text{pre}} - \mathbf{Y}_{0,\text{pre}} \mathbf{w} \right\|_2^2
$$

where $\mathbf{y}_{1,\text{pre}} \in \mathbb{R}^{T_0}$ is the pre-treatment outcome vector for the treated unit and $\mathbf{Y}_{0,\text{pre}} \in \mathbb{R}^{T_0 \times N_0}$ is the pre-treatment outcome matrix for the donor units. The objective is to minimize the mean squared error (MSE) between the pre-treatment outcomes of the treated unit and the synthetic control.

$$
\mathcal{W} = \left\{ \mathbf{w} \in \mathbb{R}^{N_0} : \mathbf{w} \geq 0, \|\mathbf{w}\|_1 = 1 \right\}
$$

Once the weights $\mathbf{w}$ are estimated, the counterfactual outcome for the treated unit during the post-treatment period is given by

$$
\mathbf{y}_{1,t}^{\text{SC}} = \mathbf{Y}_0 \mathbf{w}, \quad \text{for } t > T_0
$$

Thus, the counterfactual outcome for each time period in the post-treatment period is the weighted sum of the donor units' outcomes, with the weights derived from the pre-treatment period.

# Synthetic Regression Control (SRC)

---
title: "Synthetic Regularized Control (SRC) Estimation Procedure"
format: html
---

The SRC estimation procedure consists of three stages: estimation of alignment coefficients, estimation of the noise variance, and penalized optimization of donor weights. Let $\mathbf{y}_1^{\text{pre}} \in \mathbb{R}^{T_0}$ denote the pre-treatment outcomes of the treated unit, and let $\mathbf{Y}_0^{\text{pre}} \in \mathbb{R}^{T_0 \times J}$ denote the corresponding outcomes for the $J$ donor units. To account for level differences, we first demean both the treated and donor series. The demeaned treated outcome vector is given by $\widetilde{\mathbf{y}}_1 = \mathbf{y}_1^{\text{pre}} - \frac{1}{T_0} \mathbf{1}^\top \mathbf{y}_1^{\text{pre}} \cdot \mathbf{1}$, and the demeaned donor matrix is $\widetilde{\mathbf{Y}}_0 = \mathbf{Y}_0^{\text{pre}} - \frac{1}{T_0} \mathbf{1} \mathbf{1}^\top \mathbf{Y}_0^{\text{pre}}$.

For each donor unit $j$, an alignment coefficient $\hat{\theta}_j$ is computed by projecting $\widetilde{\mathbf{y}}_1$ onto the corresponding column $\widetilde{\mathbf{Y}}_{0,j}$ of the demeaned donor matrix. This yields $\hat{\theta}_j = \frac{\widetilde{\mathbf{y}}_1^\top \widetilde{\mathbf{Y}}_{0,j}}{\| \widetilde{\mathbf{Y}}_{0,j} \|^2}$ for $j = 1, \dots, J$. These coefficients collectively form the vector $\hat{\boldsymbol{\theta}} \in \mathbb{R}^J$. We then define the alignment-adjusted donor matrix $\mathbf{Y}_\boldsymbol{\theta} = \mathbf{Y}_0^{\text{pre}} \cdot \mathrm{diag}(\hat{\boldsymbol{\theta}})$, which rescales each donor column by its alignment with the treated unit.

To estimate the residual noise variance $\hat{\sigma}^2$, we define the centering matrix $\mathbf{Q} = \mathbf{I}_{T_0} - \frac{1}{T_0} \mathbf{1} \mathbf{1}^\top$. We then form the matrix $\mathbf{G} = \mathbf{Y}_0^{\text{pre}^\top} \mathbf{Q} \mathbf{Y}_0^{\text{pre}}$ and extract its diagonal to normalize the projection. This gives the projection operator $\mathbf{Z} = \mathbf{Y}_0^{\text{pre}} \cdot \mathrm{diag}(\mathrm{diag}(\mathbf{G})^{-1}) \cdot \mathbf{Y}_0^{\text{pre}^\top}$. The residual is then computed as $\mathbf{r} = \mathbf{Q} \mathbf{y}_1^{\text{pre}} - \mathbf{Q} \mathbf{Z} \mathbf{Q} \mathbf{y}_1^{\text{pre}}$, and the estimated noise variance is $\hat{\sigma}^2 = \| \mathbf{r} \|^2$.

With $\hat{\boldsymbol{\theta}}$ and $\hat{\sigma}^2$ in hand, we solve a penalized least squares problem to obtain donor weights. Specifically, we minimize the objective $\| \mathbf{y}_1^{\text{pre}} - \mathbf{Y}_\boldsymbol{\theta} \mathbf{w} \|^2 + 2 \hat{\sigma}^2 \cdot \mathbf{1}^\top \mathbf{w}$, subject to the constraints $\mathbf{1}^\top \mathbf{w} = 1$ and $\mathbf{w} \geq \mathbf{0}$. The solution $\hat{\mathbf{w}}$ balances goodness-of-fit with regularization based on the estimated noise.

Finally, we construct predictions. Let $\bar{y}_1 = \frac{1}{T_0} \mathbf{1}^\top \mathbf{y}_1^{\text{pre}}$ be the mean of the treated unit in the pre-treatment period, and let $\bar{\mathbf{y}}_0 = \frac{1}{T_0} \mathbf{Y}_0^{\text{pre}^\top} \mathbf{1}$ be the vector of donor means. Define $\mathbf{Y}_0^{\text{post}} \in \mathbb{R}^{T_1 \times J}$ as the donor outcomes in the post-treatment period. The in-sample fit is given by $\hat{\mathbf{y}}_1^{\text{pre}} = \mathbf{Y}_0^{\text{pre}} (\hat{\boldsymbol{\theta}} \odot \hat{\mathbf{w}})$, and the post-treatment counterfactual is constructed as $\hat{\mathbf{y}}_1^{\text{post}} = \bar{y}_1 \cdot \mathbf{1} + (\mathbf{Y}_0^{\text{post}} - \mathbf{1} \bar{\mathbf{y}}_0^\top)(\hat{\boldsymbol{\theta}} \odot \hat{\mathbf{w}})$, where $\odot$ denotes element-wise multiplication.

```{python}

import pandas as pd
from mlsynth.mlsynth import SRC, FSCM
import matplotlib.pyplot as plt
import matplotlib

# matplotlib theme
jaredplot = {'axes.grid': True,
              'grid.linestyle': '--',
              'legend.framealpha': 1,
              'legend.facecolor': 'white',
              'legend.shadow': True,
              'legend.fontsize': 14,
              'legend.title_fontsize': 16,
              'xtick.labelsize': 14,
              'ytick.labelsize': 14,
              'axes.labelsize': 16,
              'axes.titlesize': 20,
              'figure.dpi': 100}

matplotlib.rcParams.update(jaredplot)

# URL to fetch the dataset
url = 'https://raw.githubusercontent.com/jgreathouse9/mlsynth/refs/heads/main/basedata/basque_data.csv'
df = pd.read_csv(url)

treat = df.columns[-1]
time = df.columns[1]
outcome = df.columns[2]
unitid = df.columns[0]

config = {
    "df": df,
    "treat": treat,
    "time": time,
    "outcome": outcome,
    "unitid": unitid,
    "display_graphs": False,
    "counterfactual_color": "blue"
}

# Create instances of each model with the config dictionary
models = [SRC(config), FSCM(config)]


results = []
for model in models:
    result = model.fit()
    results.append((type(model).__name__, result))  # Store the model name and result as a tuple

plt.figure(figsize=(10, 6))
plt.axvline(x=20, color='red', linestyle=':', label="Terrorism")

for model_name, result in results:
    counterfactual = result["Vectors"]["Counterfactual"]
    # Plot the Counterfactual vs Observed Unit with dynamic labels
    plt.plot(counterfactual, label=f"{model_name} Basque", linestyle='--')
observed_unit = result["Vectors"]["Observed Unit"]
plt.plot(observed_unit, label=f"Basque", color='black', linewidth=2)

plt.xlabel('Time Periods')
plt.ylabel('GDP per Capita')
plt.title('Synthetic Regression Control Versus Forward SCM')
plt.legend()

plt.show()
```
