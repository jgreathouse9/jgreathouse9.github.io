---
title: 'What is a Synthetic Control?'
date: 2025-08-12
categories: [Econometrics, Causal Inference]
---

[Marketers](https://www.stellaheystella.com/blog/the-new-age-of-marketing-measurement-ai-incrementality-testing) stress the importance of location selection for geo-testing. In other words, you can't simply take a pure average of your control group regions/all the places you advertise. Marketers and economists require systematic control group selection methods, using a variety of methods for their incrementality methods.


In order to do this though, we need to take a step back. We need to ask ourselves more fundamentally what we think a valid counterfactual in this setting is. This happens in academia or industry, where my coworkers will ask me questions like,  
"Hey Jared, how do you view the whole constraints upon the weights for synthetic control methods? Why do we care, if at all, that the weights should be non-negative or add up to anything, and are there any rules regarding these ideas?" My answer is usually some variant of: *"Well, it depends on what you think a synthetic control is."*  

Classically, synthetic control weights are viewed as a sparse vector, and plenty of academic work has [developed](https://doi.org/10.1080/15140326.2024.2361184) synthetic control methodologies from this perspectiveâ€”focusing on sparsity for interpretability and parsimony.

[Others](https://doi.org/10.1111/jofi.13298) [argue](https://doi.org/10.48550/arXiv.2312.05593) [however](https://www.researchgate.net/profile/Yishu_Wang15/publication/386176990_L2-relaxation_for_Economic_Prediction/links/6747d57f876bd17778297bad/L2-relaxation-for-Economic-Prediction.pdf) that while sparsity offers interpretability, it may not always be practical for capturing the complex relationships in real economic or business phenomena. Instead, they advocate for dense coefficient vectors that distribute weights more diffusely across donors, potentially improving predictive performance.

In my opinion, the general form of a synthetic control problem is some objective function where we weight donor units to best approximate the treated (set of) unit(s), with the choice of constraints reflecting both the econometric goals and domain-specific beliefs. The most general expression for this is

$$
\begin{aligned}
\min_{\mathbf{w}} \quad & \mathcal{L}\big( \mathbf{y}_1, \mathbf{Y}_0 \mathbf{w} \big) + \lambda \cdot \mathcal{R}(\mathbf{w}) \quad \text{subject to} \quad & \mathbf{w} \in \mathcal{W}
\end{aligned}
$$

where $\mathbf{y}_1$ is the vector of observed outcomes for the treated unit(s) during the pre-treatment period, $\mathbf{Y}_0$ is the matrix of outcomes for the donor pool units over the same period, and $\mathbf{w}$ is the vector of weights assigned to those donor units. The function $\mathcal{L}(\cdot, \cdot)$ represents the loss function measuring the discrepancy between the treated outcomes and the weighted combination of donors, commonly the squared error loss. The term $\mathcal{R}(\mathbf{w})$ is a regularization function that imposes additional structure or penalties on the weights to reflect beliefs or promote certain properties like sparsity or smoothness. The scalar $\lambda \geq 0$ controls the trade-off between fitting the data closely and respecting the regularization. Finally, the set $\mathcal{W}$ defines the feasible set of weights, encoding constraints such as non-negativity, sum-to-one, or other domain-specific restrictions. Notice that this setup is intended to be very very general. I have not yet taken a position on the nature of the weights or the specifics of the optimization problem.


```{python}
#| fig-align: center
#| ec: false

import pandas as pd
import numpy as np
import cvxpy as cp
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import matplotlib

# --- Plotting Setup ---
plot_theme_settings = {
    "figure.facecolor": "white",
    "figure.figsize": (11, 5),
    "figure.dpi": 100,
    "figure.titlesize": 16,
    "figure.titleweight": "bold",
    "lines.linewidth": 1.2,
    "patch.facecolor": "#0072B2",
    "xtick.direction": "out",
    "ytick.direction": "out",
    "font.size": 14,
    "font.family": "sans-serif",
    "font.sans-serif": ["DejaVu Sans"],
    "axes.grid": True,
    "axes.facecolor": "white",
    "axes.linewidth": 0.1,
    "axes.titlesize": "large",
    "axes.titleweight": "bold",
    "axes.labelsize": "medium",
    "axes.labelweight": "bold",
    "axes.spines.top": False,
    "axes.spines.right": False,
    "axes.spines.left": False,
    "axes.spines.bottom": False,
    "axes.titlepad": 25,
    "axes.labelpad": 20,
    "grid.alpha": 0.1,
    "grid.linewidth": 0.5,
    "grid.color": "#000000",
    "legend.framealpha": 0.5,
    "legend.fancybox": True,
    "legend.borderpad": 0.5,
    "legend.loc": "best",
    "legend.fontsize": "small",
}

# Apply the settings globally
matplotlib.rcParams.update(plot_theme_settings)


# === Load and parse data ===
df = pd.read_csv(r"Data/scm_counterfactuals.csv")

extracted = {"sparse": {}, "dense": {}}

for col in df.columns:
    if col.startswith("sparse_"):
        model_name = col[len("sparse_"):]
        extracted["sparse"][model_name] = df[col].to_numpy()
    elif col.startswith("dense_"):
        model_name = col[len("dense_"):]
        extracted["dense"][model_name] = df[col].to_numpy()

if "CLUSTERSC" in extracted["dense"]:
    extracted["dense"]["PCR"] = extracted["dense"].pop("CLUSTERSC")
if "CLUSTERSC" in extracted["sparse"]:
    extracted["sparse"]["RPCA"] = extracted["sparse"].pop("CLUSTERSC")

T0 = (df["treatment"] == 0).sum()
y = df["observed"].to_numpy()
y_pre = y[:T0]

def fit_weights(y, Y0, lambda_):
    n, m = Y0.shape
    w = cp.Variable(m, nonneg=True)
    residual = y - Y0 @ w
    obj = cp.Minimize(cp.sum_squares(residual) + lambda_ * cp.sum_squares(w))
    constraints = [cp.sum(w) == 1]
    prob = cp.Problem(obj, constraints)
    prob.solve()
    return w.value

def cross_validate_lambda(y_pre, Y0_pre, lambdas, k_folds=5, random_state=42):
    kf = KFold(n_splits=k_folds, shuffle=True, random_state=random_state)
    avg_errors = []
    for lambda_ in lambdas:
        fold_errors = []
        for train_idx, test_idx in kf.split(y_pre):
            y_train, y_test = y_pre[train_idx], y_pre[test_idx]
            Y_train, Y_test = Y0_pre[train_idx], Y0_pre[test_idx]
            try:
                w_hat = fit_weights(y_train, Y_train, lambda_)
                y_pred = Y_test @ w_hat
                fold_errors.append(np.mean((y_test - y_pred) ** 2))
            except:
                fold_errors.append(np.inf)
        avg_errors.append(np.mean(fold_errors))
    best_lambda = lambdas[np.argmin(avg_errors)]
    return best_lambda, avg_errors

lambda_grid = np.logspace(-3, 2, 100)

results = {}
for group in ["sparse", "dense", "all"]:
    if group == "all":
        models = {**extracted["sparse"], **extracted["dense"]}
    else:
        models = extracted[group]

    model_names = list(models.keys())
    Y0 = np.column_stack([models[name] for name in model_names])
    Y0_pre = Y0[:T0]

    best_lambda, _ = cross_validate_lambda(y_pre, Y0_pre, lambda_grid)
    w_opt = fit_weights(y_pre, Y0_pre, best_lambda)
    y_hat_pre = Y0_pre @ w_opt
    rmse = np.sqrt(np.mean((y_pre - y_hat_pre) ** 2))

    results[group] = {
        "rmse": rmse,
        "lambda": best_lambda,
        "weights": dict(zip(model_names, w_opt)),
        "model_names": model_names,
        "Y0": Y0
    }

indiv_rmses = {}
for group in ["sparse", "dense"]:
    models = extracted[group]
    for name, series in models.items():
        rmse = np.sqrt(np.mean((y_pre - series[:T0]) ** 2))
        indiv_rmses[name] = rmse

for group in ["sparse", "dense", "all"]:
    indiv_rmses[f"{group} average"] = results[group]["rmse"]

sorted_names = sorted(indiv_rmses, key=lambda k: indiv_rmses[k], reverse=True)
sorted_rmses = [indiv_rmses[name] for name in sorted_names]


# === Plot side-by-side instead of stacked ===
fig = plt.figure()
gs = gridspec.GridSpec(1, 2, width_ratios=[3, 2], wspace=0.3)

# Left plot: observed and model averages
ax0 = fig.add_subplot(gs[0])
ax0.plot(y, label="Observed", color="black", linewidth=3)

colors = {"sparse": "red", "dense": "blue", "all": "purple"}

for group in ["sparse", "dense", "all"]:
    if group == "all":
        models = {**extracted["sparse"], **extracted["dense"]}
    else:
        models = extracted[group]

    model_names = list(models.keys())
    Y0 = np.column_stack([models[name] for name in model_names])

    w = np.array([results[group]["weights"].get(name, 0) for name in model_names])
    y_hat = Y0 @ w

    ax0.plot(y_hat, label=f"{group.capitalize()} Model Avg", color=colors[group], linewidth=1.5)

ax0.axvline(x=T0-1, color="grey", linestyle="--", label="Treatment Start")
ax0.set_xlabel("Time")
ax0.set_ylabel("Outcome (YoY Growth)")
ax0.set_title("Observed vs Model-Averaged Synthetic Controls")
ax0.legend()
ax0.text(50, -20, f"Sparse RMSE: {results['sparse']['rmse']:.4f}", color="red", fontsize=12)
ax0.text(50, -22, f"Dense RMSE: {results['dense']['rmse']:.4f}", color="blue", fontsize=12)

# Right plot: horizontal RMSE bar chart
ax1 = fig.add_subplot(gs[1])
bars = ax1.barh(range(len(sorted_names)), sorted_rmses, color="skyblue")
ax1.set_yticks(range(len(sorted_names)))
ax1.set_yticklabels(sorted_names, rotation=45)
ax1.invert_yaxis()
ax1.set_xlabel("Pre-treatment RMSE")
ax1.set_title("RMSEs of Individual and Averaged Models")

for bar, rmse in zip(bars, sorted_rmses):
    width = bar.get_width()
    ax1.text(width + 0.01, bar.get_y() + bar.get_height()/2, f"{rmse:.3f}",
             va='center', fontsize=9)

plt.tight_layout()
plt.show()
```

