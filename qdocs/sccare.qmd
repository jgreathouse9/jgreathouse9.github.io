---
title: 'Synthetic Controls Do Not Care What Your Donors Are. So Why Do You?'
date: 2025-05-12
categories: [Econometric Theory]
---

# The Importance of Theory

Many people do not understand the math behind the methods they use. If you asked most DS employes who work with causal inference to formally prove when parallel trends holds like Pedro Sant'Anna does, or derive the bias bound of a new SCM as Abadie might, we likely would not have very many contenders. And that's okay, that's natural. After all, DS is a very applied field; the langauge of proof and formal math are typically far flung concerns of your typical data scientist, and I am certainly not an exception to this rule.

However, be that as it may, it is still important to know a little about why what you are doing is effective to begin with. Why? Well, intuition can only take us so far. Yeah, you may have a library like ```mlsynth``` or ```geolift``` on you machine (or whatever you run your code in), but how do you know which tool to use, when,. and why? More importantyl, what happens when something breaks and you do not get the results you expected? What if you get something wrong? Of course, some of this is black-box-y, but in my experience anyways, lots of the issues people run into are not research issues in the sense that their question is poor or the estimator is wrong; instead, they simply misunderstand or do not know econometric theory. And this fact is usually obvious from the problems they run into. Again, this is not an issue of proof or technical depth; it is about knowing why your toolkit is effective.

[Ostensibly,](https://www.linkedin.com/posts/venkat-raman-analytics_why-advanced-difference-in-differences-did-activity-7318168653907025922-sQp_?utm_source=share&utm_medium=member_desktop&rcm=ACoAAB2Q8asBlsCYlwKJgJ488VWbcV1CX14FdOw) there are myths about SCM and its efficacy relative to DID, specifically "the myth that SCM/[Augmented] SCM don't have assumptions like parallel trends". I do not know who believes this myth, and if you do, [direct them to me](https://jgreathouse9.github.io/docs/consulting.html). Still, even there are not many people who confidently say "SCM has no assumptions", this is certainly the way many researchers act in practice. And that is the point of this post.

# Basic SCM

People often bring up the condition of perfect pre-intervention fit as an assumption of SCM; this [has been](https://arxiv.org/pdf/2211.12095) [revised](https://doi.org/10.3982/QE1596) [substantially](https://arxiv.org/pdf/2108.13935) in recent years, but there's another one that people do not comment on enough: the idea of the linear factor model (or [latent variable model](https://www.jmlr.org/papers/volume19/17-777/17-777.pdf))

$$
Y_{it}(0) = \boldsymbol{\lambda}_t^\top \boldsymbol{\mu}_i + \varepsilon_{it}.
$$

What does this mean? It simply means that our outcome are generated by a set of unit specific factors that are time invariant, and a set of time variant factors that are common across all units. These factors may indeed affect each unit differently... but they are common across units. SCM [fundamentally](https://osf.io/preprints/socarxiv/fc9xt_v1) is about matching our treated unit's common factors to the common factors that we believe are embedded in the donor set (see conditons 1-6 [here](https://arxiv.org/pdf/2211.12095), such that unobservable heteorgeneity goes away and we have a good enough match between our donor pool an the target unit. In other words, this is the whole motivation for synthetic control in the very first place, the notion that we are predicting a counterfactual using control units that behave similarly, **regardless** of which units those happen to be.

A more flexible idea is [the fine-grained potential outcomes model](https://proceedings.mlr.press/v151/shi22b/shi22b.pdf), which shifts the unit of analysis from groups (e.g., states, regions) to individuals within groups or regions. In this framework, groups are treated as distributions of individuals, and the goal is to estimate the ATT for the treated unit’s population. This model also allows for diverse donor types provided the aggregated donor outcomes reflect individuals who are exchangeable with the treated unit’s population. The practical implication of this is that when we apply these panel data models to real life settings, we are allowed to use different donor typs on the condition that they help us learn about the trajector of the target unit in the pre-intervention period. Because SCM does not care about what kind of donors you use, so long as they are informative donors.

# Application

Don't believe me? Let's replicate some results shall we. We know the classic example of Prop 99, where California's anti-tobacco program was compared to 38 donor states. But California is a [ridiculously large](https://www.gov.ca.gov/2025/04/23/california-is-now-the-4th-largest-economy-in-the-world/) economy, and is basically a small country by many metrics. So why do we need to use other states as the comparison units? Why can we not use larger, aggregated control units? It turns our that we can do just that. Here, I compare California to [the donor divisions of the United States](https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf), where the outcome (tobacco smoking per capita) for the donor units are averaged over time at the division level and California's remains as is.

```{python}
#| echo: false
#| fig-align: center
import pandas as pd
from mlsynth.mlsynth import FDID, TSSC, PDA

# URL of the .dta file
url = "http://fmwww.bc.edu/repec/bocode/s/scul_p99_region.dta"

# Load the Stata file directly from the URL
df = pd.read_stata(url)

df["Proposition 99"] =  ((df["region"] == "California") & (df["year"].dt.year >= 1989)).astype(int)

# Base configuration
base_config = {
    "df": df,
    "outcome": df.columns[2],
    "treat": df.columns[-1],
    "unitid": df.columns[0],
    "time": df.columns[1],
    "display_graphs": True,
    "save": False,
    "counterfactual_color": ["blue"]
}

# TSSC model
tssc_config = base_config.copy()  # Start with base and modify if necessary
arco = TSSC(tssc_config).fit()
```

Here is TSSC estimator, where we adjust for an intercept.

```{python}
#| echo: false
#| fig-align: center

# PDA model with method 'l2'
pda_config = base_config.copy()
pda_config["method"] = "l2"
arcol2 = PDA(pda_config).fit()
```
Here is $\ell_2$-PDA estimator.

```{python}
#| echo: false
#| fig-align: center
# FDID model
fdid_config = base_config.copy()
arcofdid = FDID(fdid_config).fit()
```

Here is the predictions of the FDID estimator. The qualitative takwaway is that these all produce very similar predictions to the baseline estimates. Even though we have reduced the donor pool by 30 units, we still maintain enough variation in the donor set to predict California's pre-treatment trends, and so long as we're doing that, we may generally use as many or as little relevant donors as we like.


# Takeaway

The point of this is not that donors in general do not matter. I wrote ```mlsynth``` precisely because I take donor selection seriosuly, so we use methods such as Forward Selection, clustering, or other avenues to choose the right donors. The key issue though is that the "right donors" do not necessarily need to be the same type of unit as the kind you are using. What matters is the relevance of the donor pool, as well as the richness of it so that we can construct better synthetic controls. If that means you compare buyers of one product to buyers of other products in online advertising, or an unusually large state/city to nations or states, then you do that.

Note that these conclusions are valid becasue of the underlying econometric theory. If you do not know the basic theory of when we may or may not use SCM, you may be making wrong decisions in your modeling strategy, or you may not be taking advantage of existing study qualities to make your analyses better. Whether or not you can do the proofs in the papers I cited above matters less than whether you can understand what they mean for the applied econometrician/data scientist so that you may employ the theoretical implications to your case.
