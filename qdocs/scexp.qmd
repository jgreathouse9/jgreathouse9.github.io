---
title: 'Synthetic Controls for Marketing Experiments'
date: 2025-09-20
categories: [Experiments, Econometrics]
---

# The Difficulties of Market Experimentation

[Suppose the government of Curaçao](https://www.travelpulse.com/news/destinations/curacao-takes-proactive-steps-toward-sustainability-amid-global-overtourism) wants to implement a new ["Green Stay" initiative](https://www.businesstravelnewseurope.com/Accommodation/HRS-Green-Stay-updates-are-set-to-increase-hotel-participation) that encourages hotels to adopt sustainability measures, such as reducing water usage, improving waste management, and shifting toward renewable energy. Such initiatives are becoming [increasingly](https://www.travelandtourworld.com/news/article/aruba-manchebo-beach-resort-and-spa-reinforces-sustainable-practices-now-with-green-globe-platinum-recertification/) [popular](https://www.travelagewest.com/Travel/Caribbean/eco-hotels-caribbean) in recent years. But evaluating whether these policies actually work presents a fundamental challenge for market researchers.  

From a methodological standpoint, the ideal approach would be a randomized controlled trial (RCT), in which some hotels implement the policy while others serve as controls. Randomization ensures that treated and control groups are balanced *in expectation*, so that any differences in outcomes after implementation can be attributed to the policy. RCTs provide a clear framework for statistical inference and are widely regarded as the gold standard for impact evaluation.  

In practice, however, conducting an RCT in this context is fraught with challenges. Ethically, randomly granting some hotels the benefits of the program while denying them to others may be perceived as unfair, particularly if the policy enhances reputation, attracts eco-conscious travelers, or provides financial advantages. Politically, coordinating randomization across hundreds of hotels would require buy-in from government agencies, hotel associations, and local businesses, some of whom may resist being “experimented on.” Tourism being central to the island’s economy, any perception of risk could provoke public concern. Logistically, enforcing varying sustainability requirements across many independent hotels would be complex and costly, making large-scale randomization impractical.  

A more feasible alternative is to focus on the market at a cluster level, grouping neighborhoods that share similar characteristics, such as geographic location, customer demographics, or historical tourist activity. Clustering mitigates ethical concerns, because selection occurs within naturally similar groups rather than arbitrarily across the entire market. It also reduces logistical complexity: interventions can be coordinated at the cluster level, and within each cluster, neighborhoods chosen as treated or control reflect the cluster’s underlying dynamics rather than idiosyncratic behavior.  

The question then becomes: how do we select which neighborhoods to treat and which to use as controls? We could throw darts at a map to decide, but this is unlikely to produce reliable estimates. Instead, the goal should be to select both a treated group of units and a control group of units which look like the cluster/group level aggregate. [Synthetic control methods](https://arxiv.org/abs/2108.02196) offer a solution, constructing "synthetic treated units" and "synthetic control units" that closely mimic the characteristics of clusters, enabling rigorous estimation of treatment effects even when randomization is infeasible.  


# Notation and Synthetic Control Designs

## Setup

As usual, this is where I get into the math details. In our Curaçao Green Stay example, the unit of treatment is the neighborhood, not individual hotels. That is, entire neighborhoods may adopt sustainability measures, while others remain untreated. Let $\mathcal{J} = \{1, \dots, J\}$ denote neighborhoods observed over $T_0$ pre-treatment periods $\mathcal{T}_0 = \{1, \dots, T_0\}$, nested within $K$ clusters $\mathcal{K} = \{1, \dots, K\}$ that group neighborhoods with similar characteristics (e.g., location, tourist demographics, historical occupancy). Let $I_k \subseteq \mathcal{J}$ denote neighborhoods in cluster $k$, with $j \in I_{k(j)}$ indicating cluster membership.

In our case, we have 21 units of interest, where some will be treated and others will not. We have 128 pre-treatment periods, and 28 post periods. Observed outcomes, like occupancy rates or energy use, are collected in the matrix $\mathbf{Y} \in \mathbb{R}^{J \times T_0}$, with $y_{jt}$ representing the outcome for neighborhood $j$ at time $t$. Potential outcomes are $y_{jt}^I$ if the neighborhood participates in Green Stay and $y_{jt}^N$ if not. The cluster-weighted average treatment effect is

$$
\tau_t = \sum_{j=1}^J f_j \, (y_{jt}^I - y_{jt}^N), \quad t > T_0,
$$

where $f_j \ge 0$ and $\sum_{j=1}^J f_j = 1$, denoting the mean treatment effect of observed compared to controls. Predictor vectors $\mathbf{x}_j \in \mathbb{R}^r$ capture pre-treatment characteristics of neighborhoods, such as the average energy use, hotel occupancy, or typical guest demographics, with cluster means being

$$
\mathbf{\bar{x}}_k = \frac{\sum_{j \in I_k} f_j \mathbf{x}_j}{\sum_{j \in I_k} f_j}.
$$

We define synthetic treated and control neighborhoods via weights $w_j \ge 0$ and $v_{j} \ge 0$ respectively, and neighborhoods are either treated or not as the decision variable $z_j \in \{0,1\}$. The clustered synthetic control estimator is obtained by solving

$$
\min_{(\mathbf{w},\mathbf{v}) \in \mathcal{F}} \; \mathcal{L}(\mathbf{w},\mathbf{v}),
$$

where $\mathcal{F}$ is the feasible set defined by nonnegativity, within–cluster normalization, exclusivity, and any budget constraints. Each cluster $k \in \{1,\dots,K\}$ has member indices $I_k$, cluster mean $\mathbf{\bar{x}}_k$, and outcomes $\mathbf{X}_{I_k}$.

## The Optimization

The optimization problem chooses synthetic treated and control neighborhoods by minimizing a loss function subject to feasibility constraints. At its core, the method constructs weighted averages of units to be treated and untreated, such that both averages resemble the cluster as a whole and each other. In addition to the above, we also may face operational costs $\mathbf{c}$ and cluster budgets $B_k$ which constrain feasible assignments. The feasible set is

$$
\begin{aligned}
\mathcal{F} = \Big\{ (w,v) \,\Big| \;
& w_j, v_j \ge 0, \quad \sum_{j \in I_k} w_j = \sum_{j \in I_k} v_j = 1, \\
& w_j \le z_j, \; v_j \le 1 - z_j, \quad \sum_{j \in I_k} z_j \in [m_{\text{min},k}, m_{\text{max},k}], \\
& \sum_{j \in I_k} c_j w_j \le B_k, \quad \sum_{k=1}^K \sum_{j \in I_k} c_j w_j \le B_{\text{total}}, \\
& \sum_{k=1}^K z_{j,k} \le 1
\Big\}.
\end{aligned}
$$

Non-negativity and normalization ($w_j, v_j \ge 0$, $\sum w_j = \sum v_j = 1$) mean that synthetic neighborhoods are weighted averages of real neighborhoods. Summing to one ensures each synthetic neighborhood is on the same scale as the real neighborhoods. The decision variable $z_j \in \{0,1\}$, together with $w_j \le z_j$ and $v_j \le 1 - z_j$, asks whether a unit should be treated. A treated neighborhood contributes to the synthetic treated unit but not the control unit, and vice versa, so that each neighborhood contributes to only one synthetic assignment, avoiding overlap between treated and control contributions. Cardinality constraints ($\sum z_j \in [m_{\text{min},k}, m_{\text{max},k}]$) ensure that at least one neighborhood is treated per cluster, but not all. Budget constraints ($\sum c_j w_j \le B_k$, $\sum c_j w_j \le B_{\text{total}}$) account for heterogeneous costs across neighborhoods.

## Variations

Abadie and Zhou propose numerous ways of implementing the synthetic control design. The base experimental SC estimator is the most straightforward. For each cluster \(k\), it tries to make the synthetic treated and synthetic control neighborhoods look like the cluster mean:

$$
\mathcal{L}_{\text{Base}}(\mathbf{w},\mathbf{v}) = \sum_{k=1}^K \Big( \mathbf{f}_{I_k}^\top \mathbf{1} \Big) \Big[
\|\bar{\mathbf{x}}_k - \mathbf{X}_{I_k}^\top \mathbf{w}_{I_k}\|_2^2
+ \|\bar{\mathbf{x}}_k - \mathbf{X}_{I_k}^\top \mathbf{v}_{I_k}\|_2^2
\Big].
$$

This design ensures that both sides of the experiment are anchored to the same benchmark, namely the cluster mean. The weakly targeted version extends this idea by also encouraging the treated and control groups to resemble each other directly:

$$
\mathcal{L}_{\text{Weak}}(\mathbf{w},\mathbf{v}) = \mathcal{L}_{\text{Base}}(\mathbf{w},\mathbf{v})
+ \beta \|\mathbf{X}_{I_k}^\top \mathbf{w}_{I_k} - \mathbf{X}_{I_k}^\top \mathbf{v}_{I_k}\|_2^2.
$$

In practice, this prevents the optimization from drifting toward two synthetic groups that match the cluster mean but diverge from each other. The penalized estimator takes this further by incorporating distance-based penalties that favor neighborhoods closer to the cluster center:

$$
\begin{aligned}
\mathcal{L}_{\text{Penalized}}(\mathbf{w}, \mathbf{v}) 
&= \sum_{k=1}^K \Bigg[
\underbrace{\|\bar{\mathbf{x}}_k - \mathbf{X}_{I_k}^\top \mathbf{w}_{I_k}\|_2^2}_{\text{fit treated to cluster mean}} 
+ \underbrace{\|\bar{\mathbf{x}}_k - \mathbf{X}_{I_k}^\top \mathbf{v}_{I_k}\|_2^2}_{\text{fit control to cluster mean}} \\
&\quad + \lambda_1 \underbrace{\sum_{j \in I_k} w_j \|\mathbf{X}_j - \bar{\mathbf{x}}_k\|_2^2}_{\text{treated distance penalty}} 
+ \lambda_2 \underbrace{\sum_{j \in I_k} v_j \|\mathbf{X}_j - \bar{\mathbf{x}}_k\|_2^2}_{\text{control distance penalty}}
\Bigg].
\end{aligned}
$$

This penalzies the weights for neighborhoods that are far from the cluster mean. Finally, the unit-level estimator introduces the most granular design. It not only enforces closeness to cluster means but also requires that each treated neighborhood has a tight match with its synthetic control:

$$
\begin{aligned}
\mathcal{L}_{\text{Unit}}(\mathbf{w}, \mathbf{v}) 
&= \sum_{k=1}^K \Bigg[
\underbrace{\|\bar{\mathbf{x}}_k - \mathbf{X}_{I_k}^\top \mathbf{w}_{I_k}\|_2^2}_{\text{treated fit to cluster mean}} 
+ \underbrace{\|\bar{\mathbf{x}}_k - \mathbf{X}_{I_k}^\top \mathbf{v}_{I_k}\|_2^2}_{\text{control fit to cluster mean}} \\
&\quad + \underbrace{\xi \sum_{j \in I_k} w_j \|\mathbf{X}_j - \mathbf{X}_{I_k}^\top \mathbf{v}_{I_k}\|_2^2}_{\text{unit-level treated-control match}} \\
&\quad + \underbrace{\lambda_{1,\text{unit}} \sum_{j \in I_k} w_j \|\mathbf{X}_j - \bar{\mathbf{x}}_k\|_2^2}_{\text{treated distance to cluster mean}} 
+ \underbrace{\lambda_{2,\text{unit}} \sum_{j \in I_k} v_j \|\mathbf{X}_j - \mathbf{X}_{I_k}^\top \mathbf{w}_{I_k}\|_2^2}_{\text{control distance to treated synthetic}}
\Bigg].
\end{aligned}
$$

Together, these estimators form a hierarchy. The base version establishes a simple anchor, the weak estimator prevents divergence, the penalized estimator incorporates geographic or demographic realism, and the unit-level estimator enforces fine-grained one-to-one balance. Analysts can select the design that best aligns with the goals and constraints of their study, balancing statistical rigor with practical considerations.

## Inference

After defining which neighborhoods are treated, which serve as controls, and how clusters are formed, the next step is to estimate the treatment effects and quantify the uncertainty around them. The design phase determines the structure, while the inference phase translates that structure into measurable effects.

Consider the full pre-treatment period $\mathcal{T}_0 = \{1, \dots, T_0\}$, which in the Curaçao example consists of 128 periods. We split this period into two parts: a fitting period $\mathcal{T}_1 = \{1, \dots, T_0 - |\mathcal{B}|\}$, which we use to compute the synthetic control weights $(\mathbf{w}_j, \mathbf{v}_j)$ and treatment assignments $z_j$, and a blank period $\mathcal{B} = \{T_0 - |\mathcal{B}| + 1, \dots, T_0\}$ that is withheld for placebo checks. In the example, the blank period has 28 observations. The post-treatment period is then $\mathcal{T}_2 = \{T_0 + 1, \dots, T_0 + 28\}$, the timeframe in which we observe the actual treatment effects.

For each neighborhood $j$ in a cluster, the synthetic treated and control outcomes at a given time $t \in \mathcal{T}_2$ are constructed by taking weighted averages of the relevant units. Specifically, the synthetic treated outcome is

$$
y_{j \in \mathcal{N}_1 t} = \sum_{j \in I_k, z_j = 1} w_j y_{jt},
$$

and the synthetic control outcome is

$$
y_{j \in \mathcal{N}_0 t} = \sum_{j \in I_k, z_j = 0} v_j y_{jt}.
$$

The difference between these two synthetic outcomes represents the unit-level treatment effect:

$$
\hat{\tau}_{j \in \mathcal{N}_1 t} = y_{j \in \mathcal{N}_1 t} - y_{j \in \mathcal{N}_0 t}.
$$

Within a cluster, we aggregate these unit-level effects using pre-specified weights $f_j$, which sum to one across all units in the cluster. This gives the cluster-level effect:

$$
\hat{\tau}_{k t} = \sum_{j \in I_k, z_j = 1} f_j \hat{\tau}_{j \in \mathcal{N}_1 t}.
$$

Summing across all clusters produces the overall treatment effect at time $t$:

$$
\hat{\tau}_t = \sum_{k=1}^K \hat{\tau}_{k t} = \sum_{j \in \mathcal{J}, z_j = 1} f_j \hat{\tau}_{j \in \mathcal{N}_1 t}.
$$

Although the current implementation uses weights based on the number of units in each clsuter, at some point I will allow them to specify things such as population or traffic or whaterver the analyst wishes to weight the units by.

To build confidence intervals, we use at placebo effects. These are computed in the blank set of the pre-treatment period $\mathcal{B}$ and capture the residuals when no treatment is applied. The unit-level placebo effect is

$$
\hat{\tau}_{j \in \mathcal{N}_1 t}^{\mathcal{B}} = y_{j \in \mathcal{N}_1 t} - y_{j \in \mathcal{N}_0 t}, \quad t \in \mathcal{B},
$$

and cluster-level and global placebo effects are defined similarly. By examining these distributions, we can gauge the natural fluctuations in the synthetic control differences. Split-conformal confidence intervals can be constructed. For the global effect, we take the $(1-\alpha)$ quantile of the absolute placebo effects,

$$
q_{1-\alpha} = \text{Quantile}_{1-\alpha}(|\hat{\tau}_t^{\mathcal{B}}|), \quad t \in \mathcal{B},
$$

and define the confidence interval as

$$
\mathrm{CI}_t = [\hat{\tau}_t - q_{1-\alpha}, \hat{\tau}_t + q_{1-\alpha}], \quad t \in \mathcal{T}_2.
$$

Cluster-level confidence intervals are obtained in the same way, replacing global effects with the corresponding cluster-level placebo distributions.

Finally, to assess statistical significance, permutation tests can be employed. The observed global statistic is calculated as the average absolute effect over the post-treatment period:

$$
S_{\text{obs}} = \frac{1}{|\mathcal{T}_2|} \sum_{t \in \mathcal{T}_2} |\hat{\tau}_t|.
$$

By randomly sampling permutations from placebo and post-treatment effects, we generate test statistics

$$
S_{\text{perm}}^{(b)} = \frac{1}{|\mathcal{T}_2|} \sum_{t \in \text{sample}} |\hat{\tau}_t|, \quad b = 1, \dots, B,
$$

and compute the global p-value as

$$
p_{\text{global}} = \frac{1}{B} \sum_{b=1}^B \mathbf{1}\{S_{\text{perm}}^{(b)} \ge S_{\text{obs}}\}.
$$

Cluster-level significance tests follow the exact same logic.

# Intuition

Let’s take a step back from all the matrices, weights, and constraints and ask: what does this framework actually *do* in practice? Think of the experimental synthetic control framework not as a mysterious math exercise, but as a decision-making engine for planning market experiments before we do any effect size estimation. Suppose you or I were literally hired by the government to do this. Their goal is to figure out which neighborhoods (or groups of units) should receive a treatment, like implementing sustainability initiatives, and which should serve as controls. The team does not (or should not!!!!!) make these decisions arbitrarily. Very likely, they must follow the rules of the framework spelt out to them by their clients. These constraints encode trade-offs among fairness, cost, donor pool/market representativeness, and logistical feasibility.  

Analysts first group neighborhoods into clusters that share similar characteristics such as geographic proximity, tourist demographics, historical activity, or energy usage patterns. This clustering makes it more likely that any comparison between treated and untreated neighborhoods is meaningful: we want to compare apples to apples, not oranges to pineapples. Remember in this setting, our ultimate goal is generally inference about the average treatment effect, NOT the average treatment effect on the treated. So, the analysts specify objectives. Perhaps treated neighborhoods should closely resemble the average of their cluster, or maybe we should match to the units themselves more tightly, informing us of our design decision. At the same time, there are real-world constraints, including budgets, maximum or minimum numbers of neighborhoods that can be treated, operational limitations, or ethical considerations. These are encoded in the optimization problem.  

The optimization process then selects synthetic treated and control neighborhoods. Instead of picking actual neighborhoods at random or by instinct, the framework identifies weighted combinations of neighborhoods that best satisfy the objectives and constraints with respect to the broader market our cluster. As I just mentioned, different formulations can be used. The base estimator ensures the treated and control groups reflect the cluster average. The weakly targeted estimator additionally encourages treated and control units to resemble each other. Penalized and unit-level estimators introduce more sophisticated distance or micro-level penalties, reflecting geography, demographics, or other practical considerations which we can code for. 

The experimental SC framework produces a recommendation: given the priorities and constraints, here is the set of neighborhoods that should be treated, and here is the synthetic control to compare them against.  The government or client then takes these recommendations and implements the policy, working with hotel associations, local communities, or other relevant stakeholders. Ethical and political considerations are respected because the framework allows analysts to control for fairness and logistical feasibility in advance. After the treatment is rolled out and enough time has passed, analysts can return to the synthetic control weights and use them to estimate and conduct inference about the treatment effects. The same weights that informed the design now form the backbone of the causal comparison.

The synthetic control framework is a full-cycle experimental design tool. It is not just about estimation — it is about making a good plan for who gets treated and why, under the constraints of budgets, fairness, and logistics. By adjusting parameters, analysts can explore different trade-offs. Increasing beta prioritizes representativeness of treated neighborhoods relative to the controls. This flexibility transforms the framework into a sandbox. Analysts can simulate multiple scenarios, see how treatment assignments change under different priorities, and produce recommendations that are robust, realistic, and implementable. This approach bridges the gap between theory and practice. It answers the question that truly matters for applied practitioners: given our goals, constraints, and the characteristics of our market, which neighborhoods should we treat, and why?  

# A Simple Example

I applied the experimental synthetic control method to the Curaçao Green Stay example, estimating treatment effects by constructing synthetic treated and control units with simulated data. The analysis used two optimization formulations: Mixed Integer Quadratic Programming (MIQP) and its respective Quadratic Programming (QP) relaxation. I selected 2 to 3 treated units per cluster, with pre-treatment fit assessed via root mean squared error (RMSE). Below, I summarize results for two clustering setups (two clusters and one cluster) and different penalty settings.

For the two-cluster setup (the first two plots below), both MIQP and QP formulations produced identical outcomes, suggesting that the integer constraints in MIQP did not alter the solution, making QP a computationally efficient alternative. In Cluster 1 (non-Willemstad), the pre-treatment RMSE was 0.1961, indicating an excellent fit. The control weights were distributed across six neighborhoods—Barber (0.1922), Lagún (0.1583), Oostpunt (0.1377), Santa Rosa (0.1940), Tera Corá (0.1293), and Westpunt (0.1885)—while the treated weights were assigned to Sint Willibrordus (0.3819), Soto (0.3003), and Spaanse Water (0.3179), summing to 1. In Cluster 2, Willemstad, the RMSE was slightly higher at 0.2185. Nine neighborhoods contributed to the control weights—Brievengat (0.1107), Groot Kwartier (0.1126), Hato (0.0633), Koraal Partir (0.1013), Otrobanda (0.1024), Pietermaai (0.1486), Piscadera Bay (0.1268), Sint Michiel (0.1240), and Steenrijk (0.1103), while the treated weights went to Groot Piscadera (0.2195), Saliña (0.3298), and Scharloo (0.4508), with Scharloo having the largest influence.

```{python}

#| echo: false

from mlsynth import MAREX
import pandas as pd
from mlsynth.utils.exputils import plot_cluster_full


df = pd.read_csv("https://raw.githubusercontent.com/jgreathouse9/mlsynth/refs/heads/main/basedata/Curacao_EXP_922.csv")
df_pre = df[df["time"] <= 120].copy()
#df_pre["Region"]=0

config = {"df": df,
          "unitid": "town",
          "time": "time",
          "outcome": "Y_obs",
          "T0": 128,
          "m_min": 2,
          "m_max": 3,
          "cluster": "Region",
          "program_type": "MIQP", "blank_periods": 28}

design = MAREX(config).fit()


plot_cluster_full(df,design)

```

```{python}

#| echo: false

from mlsynth import MAREX
import pandas as pd
import matplotlib.pyplot as plt
from mlsynth.utils.exputils import plot_cluster_full


df = pd.read_csv("https://raw.githubusercontent.com/jgreathouse9/mlsynth/refs/heads/main/basedata/Curacao_EXP_922.csv")
df_pre = df[df["time"] <= 120].copy()
df["Region"]=0

config = {"df": df,
          "unitid": "town",
          "time": "time",
          "outcome": "Y_obs",
          "T0": 128,
          "m_min": 1,
          "m_max": 5,
          "cluster": "Region",
          "program_type": "MIQP", "blank_periods": 28}

design = MAREX(config).fit()

plot_cluster_full(df,design)
```

When all 21 neighborhoods were treated as a single cluster using MIQP with 2 to 3 treated units, the RMSE was 0.1999, comparable to the two-cluster setup and indicating excellent fit. The control weights were spread across 18 neighborhoods—Barber (0.0721), Brievengat (0.0739), Groot Kwartier (0.0435), Groot Piscadera (0.0401), Hato (0.0690), Koraal Partir (0.0439), Oostpunt (0.0279), Pietermaai (0.0559), Saliña (0.0451), Santa Rosa (0.0620), Scharloo (0.0686), Sint Michiel (0.0608), Sint Willibrordus (0.1004), Soto (0.0309), Spaanse Water (0.0671), Steenrijk (0.0647), Tera Corá (0.0603), and Westpunt (0.0137), with each contributing 1–10% to the synthetic control. The treated weights were assigned to Lagún (0.3335), Otrobanda (0.3730), and Piscadera Bay (0.2935). In a separate one-cluster setup using MIQP with a cluster-penalized design, where penalties $\lambda_1 = 0.2$ and $\lambda_2 = 0.2$ were applied to encourage proximity to the cluster mean, the RMSE increased to 1.52. The fit quality degrades slighly, but is still acceptable. The control weights were concentrated on three neighborhoods—Santa Rosa (0.0415), Scharloo (0.7368), and Tera Corá (0.2217)—with Scharloo dominating the synthetic control. The treated weights were assigned to two neighborhoods, Pietermaai (0.5161) and Piscadera Bay (0.4839), summing to 1, reflecting a sparser solution driven by the penalties.

The results show that the unpenalized MIQP and QP formulations consistently achieved excellent pre-treatment fit, with RMSEs ranging from 0.1961 to 0.2185 in the two-cluster setup and 0.1999 in the unpenalized one-cluster setup, supporting reliable counterfactual estimation. The penalized design, however, compromised fit quality, likely due to the restrictive $\lambda_1 = \lambda_2 = 0.2$ penalties, which prioritized sparsity and proximity to the cluster mean but led to a high RMSE. Ofcourse, in reality we can choose these penalties via cross validation, instead of setting them manually, these were just chosen for the sake of example.

Treated weights were balanced across 2–3 units in all setups, ensuring no single unit dominated, while control weights varied from moderate (6–19% in two-cluster) to highly diversified (1–10% in one-cluster unpenalized) to sparse (Scharloo at 0.7368 in penalized). The identical results from MIQP and QP in the two-cluster setup suggest that the QP relaxation is a viable alternative for computational efficiency. What this shows is that the synthetic design is robust: whether we divide Curaçao into clusters or treat it as a single unit, whether we enforce integer treatment assignments or relax them, the method generally produces stable synthetic matches. Also, these data were simualted [from Wikipedia](https://en.wikipedia.org/wiki/List_of_populated_places_in_Cura%C3%A7ao), in theory [we could get both population and density data](https://www.citypopulation.de/en/curacao/admin/) on a wider variety of places in Curaçao, with a more sophisitcated hierarchical linear factor model, to see how the estimator would play with even more clusters/units.

## Takeaways for Practice

Notice that we have not yet discussed the ATT/ATE or the uncertainty of estimated treatment effects. This is because the framework above is focused on experimental design. The main goal is to decide *who should be treated* and *why* before any real-world intervention. In other words, we can be confident in the design itself—who is treated, who is not, and why—before estimating treatment effects or reporting uncertainty. The data from above was simulated without a treatment effect, suggesting that if we did apply the treatment effect, we would see if, if it were there. Crucially, in settings with few treatable units, synthetic control designs can achieve balance analogous to an RCT, even when only a handful of units are treated. In fact, Abadie and Zhou "show that synthetic control design can substantially outperform randomized designs in experimental settings with a small number of treated units." This allows interventions to be targeted strategically, saving resources while using a valid identification method.

Contrast this with a traditional RCT. In an RCT, randomization occurs once in the field. Designing an RCT is costly and requires coordination across multiple actors. We cannot experiment with different randomization schemes beforehand, since the quality of the randomization can only be assessed *after* it occurs. Once units are assigned, the study must proceed, with all associated costs, risks, and constraints. By contrast, the synthetic control design can be iterated rapidly on a laptop. We can explore different cluster groupings, penalties, cost and budget constraints, or solver formulations and observe how stable the resulting design is before committing any resources. This flexibility makes the synthetic experimentation method a powerful planning tool. It enables researchers and practitioners to prototype experiments cheaply and safely, ensuring that the data support a credible design before any real-world action. Large-scale RCTs remain the gold standard, but they are expensive and logistically demanding. Synthetic control methods open the door to an iterative, exploratory phase of experimental planning, especially in the setting where only a few units may be treated, so that when we do invest in a full study, it is built on a solid foundation that is business aware.
