---
title: "Forward Selected Synthetic Control Method"
---

Interpolation bias is a known issue in synthetic control methods. For valid counterfactual prediction, the donor units should be as similar as possible to the treated unit in the pre-treatment period. Selecting an appropriate donor pool is therefore critical, but this can be challenging in settings with many potential controls. This post introduces the [Forward Selected Synthetic Control Method](https://doi.org/10.1016/j.econlet.2024.111976). This applies Forward Selection to choose the donor pool for a synthetic control model before estimating out-of-sample predictions.

## Notation and Setup

Let $\mathbb{R}$ denote the set of real numbers. A calligraphic letter, such as $\mathcal{S}$, represents a discrete set with cardinality $S = |\mathcal{S}|$. Let $t \in \mathbb{N}$ and $j \in \mathbb{N}$ represent indices for $T$ time periods and $N$ units, respectively. The pre-treatment period consists of consecutive time periods $\mathcal{T}_1 = \{1, 2, \dots, T_0\}$, with cardinality $T_1$, while the post-treatment period is given by $\mathcal{T}_2 = \{T_0 + 1, \dots, T\}$, with cardinality $T_2$. The treated unit is indexed by $j = 1$, while the remaining control units are indexed as $\mathcal{N}_0 = \{2, \dots, N\}$, with cardinality $N_0 = N - 1$.

The observed outcome for unit $j$ at time $t$ is denoted by $y_{jt}$, where a generic outcome vector for a given unit at time $t$ is $\mathbf{y}_j \in \mathbb{R}^T$, where $\mathbf{y}_j = (y_{j1}, y_{j2}, \dots, y_{jT})^\top$. The outcome vector for the treated unit is $\mathbf{y}_1$, and the donor matrix, similarly, is defined as:

$$
\mathbf{Y}_0 \coloneqq \begin{bmatrix} \mathbf{y}_j \end{bmatrix}_{j \in \mathcal{N}_0} \in \mathbb{R}^{T \times N_0}.
$$

## Synthetic Control Optimization

The synthetic control method estimates the counterfactual outcome for the treated unit by solving the following optimization problem:

$$
\mathbf{w}^* = \underset{\mathbf{w} \in \Delta^{N_0}}{\operatorname*{argmin}} \|\mathbf{y}_1 - \mathbf{Y}_0 \mathbf{w} \|_2^2.
$$

This finds the weights $\mathbf{w}$ that minimize the squared error between the treated unit's pre-treatment outcomes and the synthetic controlâ€™s weighted average of control units. The space of synthetic control weights is the $N_0$-dimensional probability simplex:

$$
\Delta^{N_0} = \left\{ \mathbf{w} \in \mathbb{R}_{\geq 0}^{N_0} : \|\mathbf{w}\|_1 = 1 \right\}.
$$

Practically this means that the predictions will never be outside the donor pool's outcome values. The key thing is choosing the right donor units.

## Forward Selection for Donor Pool Choice

Now, consider a restricted donor pool chosen by the forward selection algorithm. This consists of a strict subset of control units, $\mathcal{S} \subseteq \mathcal{N}_0$, with cardinality $k = |\mathcal{S}|$ where $k \leq N_0$. This subset induces a subsimplex:

$$
\Delta^{k}(\mathcal{S}) = \left\{ \mathbf{w}^\prime \in \mathbb{R}_{\geq 0}^{k} : \|\mathbf{w}^{\prime}\|_1 = 1 \right\}.
$$

The forward selection algorithm builds a sequence of tuples, $(\mathcal{S}_K, \text{MSE}_K)$ after each $K$-th iteration of forward selection. The tuple contains $\text{MSE}_K$ (or the pre-treatment mean squared error) and its corresponding selected donor set $\mathcal{S}_K$ for that iteration. We begin by minimizing:

$$
\mathcal{S}_1 = \{j^\ast\}, \quad \text{where} \quad j^\ast = \underset{j \in \mathcal{N}_0}{\operatorname*{argmin}} \ \text{MSE}(\{j\}).
$$

according to the SCM optimization above. At each step, we select a single control unit that minimizes the $\text{MSE}$ when combined with the previously selected set:

$$
 j^\ast = \underset{j \in \mathcal{N}_0 \setminus \mathcal{S}_{K-1}}{\operatorname*{argmin}} \ \text{MSE}(\mathcal{S}_{K-1} \cup \{j\}).
$$

The updated tuple is:

$$
(\mathcal{S}_K, \text{MSE}_K) = (\mathcal{S}_{K-1} \cup \{j^\ast\}, \text{MSE}(\mathcal{S}_{K-1} \cup \{j^\ast\})).
$$

This process continues until all $N_0$ donors have been evaluated. The final donor set we use for analysis is the tuple with the lowest $\text{MSE}$:

$$
\mathcal{S}^{\ast} = \underset{(\mathcal{S}_K, \text{MSE}_K) \in \mathbb{T}}{\operatorname*{argmin}} \ \text{MSE}_K.
$$

Thus, $\mathcal{S}^{\ast}$ is the optimal donor pool by forward selection. Note that even within $\mathcal{S}^{\ast}$, some donors may receive zero weight in the final solution, as these are just the units selected for inclusion in the donor pool, not the ones that will actually get weight, in contrast to methods such as [Forward Difference-in-Differences](https://doi.org/10.1287/mksc.2022.0212) or the [forward selection panel data method](https://doi.org/10.1016/j.jeconom.2021.04.009), both of which are available in `mlsynth`.

## Estimation in ```mlsynth```

As ususal, we begin by installing ```mlsynth```.

```bash
pip install -U git+https://github.com/jgreathouse9/mlsynth.git
```

And then we load the Proposition 99 dataset and fit the model in the ususal ```mlsynth``` fashion.

```{python}
#| fig-align: center

import pandas as pd # To work with panel data

from IPython.display import display, Markdown # To create the table

from mlsynth.mlsynth import FSCM # The method of interest

url = "https://raw.githubusercontent.com/jgreathouse9/mlsynth/refs/heads/main/basedata/smoking_data.csv"

data = pd.read_csv(url)

# Our method inputs

config = {
    "df": data,
    "outcome": data.columns[2],
    "treat": data.columns[-1],
    "unitid": data.columns[0],
    "time": data.columns[1],
    "display_graphs": True,
    "save": False,
    "counterfactual_color": "red"}

arco = FSCM(config).fit()
```

After estimation, we can get the weights into a table like

```{python}
weights_dict = arco['Weights'][0]
df = pd.DataFrame(list(weights_dict.items()), columns=['State', 'Weight'])
display(Markdown(df.to_markdown(index=False)))
```
These are the weights for all 17 units that were selected by the algorithm. As we can see, all of these even did not ultimately contribute to the synthetic control, with only 6 being assigned positive weight. Our ATT of Prop 99 is -19.51 and the pre-treatment Root Mean Squared Error for the Forward Selected SCM is 1.66. I compared these results to the same results we get in the Stata help file, which includes the covariates that Abadie, Diamond, and Hainmuller originally adjusted for as well as customizes the period over which to minimize the MSE. The ATT using the original method is -18.97, and the RMSE for the pre-treatment period is 1.75. The corresponding weights, using the full donor pool, are 0.335 for Utah, 0.236 for Nevada, 0.2 for Montana, 0.16 for Colorado, 0.068 for Connecticut, and 0.001 for New Mexico. So as we can see, the ATTs are very similar, and the pre-treatment prediction errors are pretty much the same. By comparison, when we estimate this in Stata (omitting the auxilary covariate predictors and estimate ``` synth2 cigsale cigsale(1988) cigsale(1980) cigsale(1975) , trunit(3) trperiod(1989) xperiod(1980(1)1988) nested fig```, we get a RMSE of 4.33 and an ATT of -22.88. Furthermore, with this specification, the weights are no longer a sparse vector.

The point of this article is very simple. The original SCM works well, however it can be very sensitive to the inclusion of covariates, which covariates are included, what their lags are, and so on and so forth. Furthermore, there is also an issue of [covariate selection](
https://doi.org/10.48550/arXiv.2203.11576) in settings where we have multiple covariates. When we employ machine learning methods to select the donor pool, using outcome data only, we can get comparable results to the baseline estimates that seem to require multiple covariates in order to properly fit the pre-intervention trajectory. The promise of machine-learning methods in this space is to automate away donor selection, to some degree, which can attain similar results to the original implementations of the methodology.

In the [original paper](https://doi.org/10.1016/j.econlet.2024.111976), Giovanni uses cross-validation to estimate this model. I have not done this yet, but I will very soon. As ususal, email me with questions or comments.
